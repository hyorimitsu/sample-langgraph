{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preparation"
      ],
      "metadata": {
        "id": "eXn-ZRajmsAo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install libraries"
      ],
      "metadata": {
        "id": "-VGqFzf5mRF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain langchain_openai langgraph google-search-results"
      ],
      "metadata": {
        "id": "86CwrxzX20uY"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment settings"
      ],
      "metadata": {
        "id": "gjCXinTdmh4R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "n1cdqodT2gYq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ['SERPAPI_API_KEY'] = userdata.get('SERPAPI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "OPENAI_MODEL = \"gpt-4-turbo-preview\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define each components"
      ],
      "metadata": {
        "id": "NHOg82fCnZ77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the utility functions"
      ],
      "metadata": {
        "id": "w3KYzT63nuTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
        "  prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "      (\"system\", system_prompt),\n",
        "      MessagesPlaceholder(variable_name=\"messages\"),\n",
        "      MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        "  )\n",
        "  agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "  return AgentExecutor(agent=agent, tools=tools)\n",
        "\n",
        "def create_supervisor(llm: ChatOpenAI, agents: list[str]):\n",
        "  system_prompt = (\n",
        "    \"You are the supervisor over the following agents: {agents}.\"\n",
        "    \" You are responsible for assigning tasks to each agent as requested by the user.\"\n",
        "    \" Each agent executes tasks according to their roles and responds with their results and status.\"\n",
        "    \" Please review the information and answer with the name of the agent to which the task should be assigned next.\"\n",
        "    \" Answer 'FINISH' if you are satisfied that you have fulfilled the user's request.\"\n",
        "  )\n",
        "\n",
        "  options = [\"FINISH\"] + agents\n",
        "  function_def = {\n",
        "    \"name\": \"supervisor\",\n",
        "    \"description\": \"Select the next agent.\",\n",
        "    \"parameters\": {\n",
        "      \"type\": \"object\",\n",
        "      \"properties\": {\n",
        "        \"next\": {\n",
        "          \"anyOf\": [\n",
        "            {\"enum\": options},\n",
        "          ],\n",
        "        }\n",
        "      },\n",
        "      \"required\": [\"next\"],\n",
        "    },\n",
        "  }\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "      (\"system\", system_prompt),\n",
        "      MessagesPlaceholder(variable_name=\"messages\"),\n",
        "      (\n",
        "        \"system\",\n",
        "        \"In light of the above conversation, please select one of the following options for which agent should be act or end next: {options}.\"\n",
        "      ),\n",
        "    ]\n",
        "  ).partial(options=str(options), agents=\", \".join(agents))\n",
        "\n",
        "  return (\n",
        "    prompt\n",
        "    | llm.bind_functions(functions=[function_def], function_call=\"supervisor\")\n",
        "    | JsonOutputFunctionsParser()\n",
        "  )"
      ],
      "metadata": {
        "id": "3tzT4wb03Pta"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Tools"
      ],
      "metadata": {
        "id": "ODYgPsp-yUDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "@tool(\"researcher\")\n",
        "def researcher(query: str) -> str:\n",
        "  \"\"\"Research by SERP API\"\"\"\n",
        "  serp_api = SerpAPIWrapper()\n",
        "  return serp_api.run(query)\n",
        "\n",
        "@tool(\"writer\")\n",
        "def writer(content: str) -> str:\n",
        "  \"\"\"Write a blog\"\"\"\n",
        "  chat = ChatOpenAI()\n",
        "  messages = [\n",
        "  SystemMessage(\n",
        "    content=\"You are a blog writer specializing in IT technology. You are responsible for writing blog posts based on the content given.\"\n",
        "            \" Articles should be in markdown format.\"\n",
        "            \" You should also make it easy for the reader to read by dividing the content into sections, using tables and figures, etc.\"\n",
        "    ),\n",
        "    HumanMessage(\n",
        "      content=content\n",
        "    ),\n",
        "  ]\n",
        "  response = chat(messages)\n",
        "  return response.content"
      ],
      "metadata": {
        "id": "JfhePVkMFbv4"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Agents"
      ],
      "metadata": {
        "id": "mLRWjLFL0kCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import Runnable\n",
        "\n",
        "llm = ChatOpenAI(model=OPENAI_MODEL)\n",
        "\n",
        "def researcher_agent() -> Runnable:\n",
        "  prompt = (\n",
        "    \"You are a researcher who uses SERP API's search engine to find the most up-to-date and correct information.\"\n",
        "  )\n",
        "  return create_agent(llm, [researcher], prompt)\n",
        "\n",
        "def writer_agent() -> Runnable:\n",
        "  prompt = (\n",
        "    \"You are a blog writer specializing in IT technology.\"\n",
        "  )\n",
        "  return create_agent(llm, [writer], prompt)"
      ],
      "metadata": {
        "id": "3DCbG-VmLYsB"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Nodes"
      ],
      "metadata": {
        "id": "kF1bYwzM4czT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, Sequence, TypedDict\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "RESEARCHER = \"RESEARCHER\"\n",
        "WRITER = \"WRITER\"\n",
        "SUPERVISOR = \"SUPERVISOR\"\n",
        "\n",
        "agents = [RESEARCHER, WRITER]\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[Sequence[BaseMessage], operator.add]\n",
        "  next: str\n",
        "\n",
        "def researcher_node(state: AgentState) -> dict:\n",
        "  result = researcher_agent().invoke(state)\n",
        "  return {\"messages\": [HumanMessage(content=result[\"output\"], name=RESEARCHER)]}\n",
        "\n",
        "def writer_node(state: AgentState) -> dict:\n",
        "  result = writer_agent().invoke(state)\n",
        "  return {\"messages\": [HumanMessage(content=result[\"output\"], name=WRITER)]}\n",
        "\n",
        "def supervisor_node(state: AgentState) -> Runnable:\n",
        "  return create_supervisor(llm, agents)"
      ],
      "metadata": {
        "id": "wYo5dUzrMXUf"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Graph"
      ],
      "metadata": {
        "id": "hy2ZAPkm6Fic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(RESEARCHER, researcher_node)\n",
        "workflow.add_node(WRITER, writer_node)\n",
        "workflow.add_node(SUPERVISOR, supervisor_node)\n",
        "\n",
        "workflow.add_edge(RESEARCHER, SUPERVISOR)\n",
        "workflow.add_edge(WRITER, SUPERVISOR)\n",
        "workflow.add_conditional_edges(\n",
        "  SUPERVISOR,\n",
        "  lambda x: x[\"next\"],\n",
        "  {\n",
        "    RESEARCHER: RESEARCHER,\n",
        "    WRITER: WRITER,\n",
        "    \"FINISH\": END\n",
        "  }\n",
        ")\n",
        "\n",
        "workflow.set_entry_point(SUPERVISOR)\n",
        "\n",
        "graph = workflow.compile()"
      ],
      "metadata": {
        "id": "pGKcqJXxOrj1"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "k3RPXigX7Px7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\n",
        "  \"Please write a blog for tech companies about the LangChain.\"\n",
        ")\n",
        "\n",
        "for s in graph.stream({\"messages\": [HumanMessage(content=prompt)]}):\n",
        "  if \"__end__\" not in s:\n",
        "    print(s)\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6sZp6-sSCA8",
        "outputId": "0989a826-a1a6-44ae-e35f-fcd0b3d1d5a7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'SUPERVISOR': {'next': 'RESEARCHER'}}\n",
            "----\n",
            "{'RESEARCHER': {'messages': [HumanMessage(content=\"# Unlocking the Potential of LangChain for Tech Companies\\n\\nIn the rapidly evolving landscape of artificial intelligence (AI) and machine learning (ML), tech companies are constantly on the lookout for groundbreaking tools and technologies that can drive innovation, enhance efficiency, and unlock new opportunities. One such technology that has recently been making waves is LangChain, a cutting-edge framework designed to leverage the power of language models for a wide range of applications. This blog post explores what LangChain is, how it works, and why it should be on the radar of every tech company aiming to stay ahead in the game.\\n\\n## What is LangChain?\\n\\nAt its core, LangChain is a framework designed to facilitate the development and deployment of applications that harness the capabilities of large language models (LLMs). It provides an abstraction layer that simplifies the integration of LLMs into various processes and applications, enabling developers to focus on building innovative solutions rather than getting bogged down by the complexities of working directly with these models.\\n\\nLangChain is built with flexibility and scalability in mind, making it suitable for a wide range of applications, from natural language processing (NLP) tasks like sentiment analysis and text summarization to more complex use cases such as automated content creation, decision-making support, and even code generation.\\n\\n## How Does LangChain Work?\\n\\nLangChain operates by providing a set of tools and APIs that abstract the complexities of interacting with LLMs. It allows developers to easily query models, process the responses, and integrate these capabilities into their applications. The framework is designed to be model-agnostic, meaning it can work with various LLMs, including OpenAI's GPT-3, Google's BERT, and others, providing a versatile toolset for developers.\\n\\nOne of the key features of LangChain is its ability to chain together multiple models and data sources, enabling more complex and nuanced applications. This chaining functionality allows for the construction of sophisticated workflows that can leverage the strengths of different models and databases, leading to more accurate and contextually relevant outcomes.\\n\\n## Why Should Tech Companies Care?\\n\\n### Unleashing Creativity and Innovation\\n\\nLangChain opens up a world of possibilities for tech companies by simplifying the integration of LLMs into their products and services. This can lead to the development of innovative features and applications that were previously too complex or resource-intensive to implement.\\n\\n### Enhancing Efficiency\\n\\nBy abstracting the complexities of working with LLMs, LangChain can significantly reduce development time and effort, allowing companies to bring new features and products to market more quickly. This increased efficiency can be a game-changer in the fast-paced tech industry.\\n\\n### Staying Competitive\\n\\nAs AI and ML continue to transform the tech landscape, companies that can effectively leverage these technologies will have a significant competitive advantage. LangChain provides a powerful tool for harnessing the potential of LLMs, enabling companies to stay at the cutting edge of innovation.\\n\\n## Conclusion\\n\\nLangChain represents a significant step forward in the integration and application of large language models in the tech industry. By simplifying the development process and unlocking new possibilities for innovation, it has the potential to revolutionize how tech companies leverage AI and ML. Whether you're looking to enhance existing products or develop entirely new offerings, LangChain offers a powerful framework that can help you harness the full potential of language models. As the technology continues to evolve, staying informed and embracing tools like LangChain will be key to staying ahead in the rapidly changing tech landscape.\", name='RESEARCHER')]}}\n",
            "----\n",
            "{'SUPERVISOR': {'next': 'FINISH'}}\n",
            "----\n"
          ]
        }
      ]
    }
  ]
}